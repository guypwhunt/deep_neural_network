{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Model Based on a Convolutional Neural Network with PyTorch\n",
    "\n",
    "The following notebook contains a Convolutional Neural Network (CNN) used to identify if an image contains a circle, square or triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import PyTorch libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Other libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from random import randint\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from random import randint\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "\n",
    "The cell beow containse an iterative loader for training data, and a second iterative loader for test data. The loaders will transform the image data into *tensors*, which are the core data structure used in PyTorch, and normalize them so that the pixel values are in a scale with a mean of 0.5 and a standard deviation of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 3 image classes:\n",
      "['circle', 'square', 'triangle']\n"
     ]
    }
   ],
   "source": [
    "# Function to ingest data using training and test loaders\n",
    "def load_dataset(data_path):\n",
    "    # Load all of the images\n",
    "    transformation = transforms.Compose([\n",
    "        # transform to tensors\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        transform=transformation\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Split into training (70% and testing (30%) datasets)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    \n",
    "    # define a loader for the training data we can iterate through in 50-image batches\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # define a loader for the testing data we can iterate through in 50-image batches\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "        \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# Now load the images from the shapes folder\n",
    "data_path = 'data/shapes/'\n",
    "\n",
    "# Get the class names\n",
    "classes = os.listdir(data_path)\n",
    "classes.sort()\n",
    "\n",
    "print('The dataset contains', len(classes), 'image classes:')\n",
    "print(classes)\n",
    "\n",
    "# Get the iterative dataloaders for test and training data\n",
    "train_loader, test_loader = load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the CNN\n",
    "\n",
    "In PyTorch, a neural network model as a class that is derived from the **nn.Module** base class. The class must define the layers in the network, and provide a **forward** method that is used to process data through the layers of the network. In the cell below the CNN is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model class defined!\n"
     ]
    }
   ],
   "source": [
    "# Create a neural net class\n",
    "class Net(nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Our images are RGB, so input channels = 3. We'll apply 12 filters in the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # We'll apply max pooling with a kernel size of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # A second convolutional layer takes 12 input channels, and generates 12 outputs\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A third convolutional layer takes 12 inputs and generates 24 outputs\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
    "        # So our feature tensors are now 32 x 32, and we've generated 24 of them\n",
    "        # We need to flatten these and feed them to a fully-connected layer\n",
    "        # to map them to  the probability for each class\n",
    "        self.fc = nn.Linear(in_features=32 * 32 * 24, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use a relu activation function after layer 1 (convolution 1 and pool)\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "      \n",
    "        # Use a relu activation function after layer 2 (convolution 2 and pool)\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        \n",
    "        # Select some features to drop after the 3rd convolution to prevent overfitting\n",
    "        x = F.relu(self.drop(self.conv3(x)))\n",
    "        \n",
    "        # Only drop the features if this is a training pass\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 32 * 32 * 24)\n",
    "        # Feed to fully-connected layer to predict class\n",
    "        x = self.fc(x)\n",
    "        # Return class probabilities via a log_softmax function \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "print(\"CNN model class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model\n",
    "\n",
    "The model can now be trained using the image data.\n",
    "\n",
    "The training consists of an iterative series of forward passes in which the training data is processed in batches by the layers in the network, and the optimizer goes back and adjusts the weights. A separate set of test images will be used to test the model at the end of each iteration (or *epoch*) so the performance improvement can be tracked as the training progresses.\n",
    "\n",
    "50 epochs are used to train the model using the batches of images loaded by the data loaders, holding back the data in the test data loader for validation. After each epoch, a loss function measures the error (*loss*) in the model and adjusts the weights (which were randomly generated for the first iteration) to try to improve accuracy. \n",
    "\n",
    "It should be noted that at this point a previously saved model is loaded to reduce the loading time of the notebook as training the model takes a considerable amount of time on mybinder. However, the code to train the model can be found here: https://mybinder.org/v2/gh/guypwhunt/deep_neural_network/HEAD?filepath=convolutional_neural_networks_pytorch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "        \n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print metrics for every 10 batches so we see some progress\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Training set [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
    "                batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss\n",
    "            \n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        batch_count = 0\n",
    "        for data, target in test_loader:\n",
    "            batch_count += 1\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += loss_criteria(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    avg_loss = test_loss/batch_count\n",
    "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return avg_loss\n",
    "    \n",
    "    \n",
    "# Now use the train and test functions to train and test the model    \n",
    "# Delete 'x =' below and uncomment the remaining code to train the model \n",
    "x = \"\"\"device = \"cpu\"\n",
    "if (torch.cuda.is_available()):\n",
    "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
    "    device = \"cuda\"\n",
    "print('Training on', device)\n",
    "\n",
    "# Create an instance of the model class and allocate it to the device\n",
    "model = Net(num_classes=len(classes)).to(device)\n",
    "\n",
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Specify the loss criteria\n",
    "loss_criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "# Train over 50 epochs\n",
    "epochs = 50\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        test_loss = test(model, device, test_loader)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Training set [0/840 (0%)] Loss: 1.103770\n",
      "Training set [500/840 (59%)] Loss: 0.767837\n",
      "Training set: Average loss: 0.825230\n",
      "Validation set: Average loss: 0.476628, Accuracy: 290/360 (81%)\n",
      "\n",
      "Epoch: 2\n",
      "Training set [0/840 (0%)] Loss: 0.511575\n",
      "Training set [500/840 (59%)] Loss: 0.308371\n",
      "Training set: Average loss: 0.388326\n",
      "Validation set: Average loss: 0.301778, Accuracy: 302/360 (84%)\n",
      "\n",
      "Epoch: 3\n",
      "Training set [0/840 (0%)] Loss: 0.354706\n",
      "Training set [500/840 (59%)] Loss: 0.261062\n",
      "Training set: Average loss: 0.256638\n",
      "Validation set: Average loss: 0.168473, Accuracy: 335/360 (93%)\n",
      "\n",
      "Epoch: 4\n",
      "Training set [0/840 (0%)] Loss: 0.168978\n",
      "Training set [500/840 (59%)] Loss: 0.117388\n",
      "Training set: Average loss: 0.138040\n",
      "Validation set: Average loss: 0.090180, Accuracy: 351/360 (98%)\n",
      "\n",
      "Epoch: 5\n",
      "Training set [0/840 (0%)] Loss: 0.100226\n",
      "Training set [500/840 (59%)] Loss: 0.065538\n",
      "Training set: Average loss: 0.071896\n",
      "Validation set: Average loss: 0.044922, Accuracy: 356/360 (99%)\n",
      "\n",
      "Epoch: 6\n",
      "Training set [0/840 (0%)] Loss: 0.034637\n",
      "Training set [500/840 (59%)] Loss: 0.036014\n",
      "Training set: Average loss: 0.043303\n",
      "Validation set: Average loss: 0.023202, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 7\n",
      "Training set [0/840 (0%)] Loss: 0.022999\n",
      "Training set [500/840 (59%)] Loss: 0.055200\n",
      "Training set: Average loss: 0.034087\n",
      "Validation set: Average loss: 0.022698, Accuracy: 357/360 (99%)\n",
      "\n",
      "Epoch: 8\n",
      "Training set [0/840 (0%)] Loss: 0.029490\n",
      "Training set [500/840 (59%)] Loss: 0.018004\n",
      "Training set: Average loss: 0.041226\n",
      "Validation set: Average loss: 0.018746, Accuracy: 359/360 (100%)\n",
      "\n",
      "Epoch: 9\n",
      "Training set [0/840 (0%)] Loss: 0.019401\n",
      "Training set [500/840 (59%)] Loss: 0.008904\n",
      "Training set: Average loss: 0.018305\n",
      "Validation set: Average loss: 0.009203, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 10\n",
      "Training set [0/840 (0%)] Loss: 0.016958\n",
      "Training set [500/840 (59%)] Loss: 0.013551\n",
      "Training set: Average loss: 0.012223\n",
      "Validation set: Average loss: 0.005830, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 11\n",
      "Training set [0/840 (0%)] Loss: 0.020725\n",
      "Training set [500/840 (59%)] Loss: 0.007458\n",
      "Training set: Average loss: 0.017074\n",
      "Validation set: Average loss: 0.004759, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 12\n",
      "Training set [0/840 (0%)] Loss: 0.006093\n",
      "Training set [500/840 (59%)] Loss: 0.003227\n",
      "Training set: Average loss: 0.008680\n",
      "Validation set: Average loss: 0.002621, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 13\n",
      "Training set [0/840 (0%)] Loss: 0.008323\n",
      "Training set [500/840 (59%)] Loss: 0.003433\n",
      "Training set: Average loss: 0.004586\n",
      "Validation set: Average loss: 0.003536, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 14\n",
      "Training set [0/840 (0%)] Loss: 0.005679\n",
      "Training set [500/840 (59%)] Loss: 0.002220\n",
      "Training set: Average loss: 0.003429\n",
      "Validation set: Average loss: 0.002008, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 15\n",
      "Training set [0/840 (0%)] Loss: 0.008813\n",
      "Training set [500/840 (59%)] Loss: 0.001869\n",
      "Training set: Average loss: 0.005016\n",
      "Validation set: Average loss: 0.003085, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 16\n",
      "Training set [0/840 (0%)] Loss: 0.010281\n",
      "Training set [500/840 (59%)] Loss: 0.002442\n",
      "Training set: Average loss: 0.003687\n",
      "Validation set: Average loss: 0.001785, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 17\n",
      "Training set [0/840 (0%)] Loss: 0.004554\n",
      "Training set [500/840 (59%)] Loss: 0.000509\n",
      "Training set: Average loss: 0.004108\n",
      "Validation set: Average loss: 0.001743, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 18\n",
      "Training set [0/840 (0%)] Loss: 0.003746\n",
      "Training set [500/840 (59%)] Loss: 0.000447\n",
      "Training set: Average loss: 0.004889\n",
      "Validation set: Average loss: 0.003176, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 19\n",
      "Training set [0/840 (0%)] Loss: 0.010371\n",
      "Training set [500/840 (59%)] Loss: 0.005106\n",
      "Training set: Average loss: 0.004751\n",
      "Validation set: Average loss: 0.002028, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 20\n",
      "Training set [0/840 (0%)] Loss: 0.002068\n",
      "Training set [500/840 (59%)] Loss: 0.000766\n",
      "Training set: Average loss: 0.002941\n",
      "Validation set: Average loss: 0.001435, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 21\n",
      "Training set [0/840 (0%)] Loss: 0.005506\n",
      "Training set [500/840 (59%)] Loss: 0.000672\n",
      "Training set: Average loss: 0.004504\n",
      "Validation set: Average loss: 0.000623, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 22\n",
      "Training set [0/840 (0%)] Loss: 0.000773\n",
      "Training set [500/840 (59%)] Loss: 0.000171\n",
      "Training set: Average loss: 0.002254\n",
      "Validation set: Average loss: 0.000901, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 23\n",
      "Training set [0/840 (0%)] Loss: 0.000373\n",
      "Training set [500/840 (59%)] Loss: 0.000964\n",
      "Training set: Average loss: 0.001514\n",
      "Validation set: Average loss: 0.000947, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 24\n",
      "Training set [0/840 (0%)] Loss: 0.003218\n",
      "Training set [500/840 (59%)] Loss: 0.001212\n",
      "Training set: Average loss: 0.001670\n",
      "Validation set: Average loss: 0.000543, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 25\n",
      "Training set [0/840 (0%)] Loss: 0.000807\n",
      "Training set [500/840 (59%)] Loss: 0.000227\n",
      "Training set: Average loss: 0.001656\n",
      "Validation set: Average loss: 0.000662, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 26\n",
      "Training set [0/840 (0%)] Loss: 0.003577\n",
      "Training set [500/840 (59%)] Loss: 0.001073\n",
      "Training set: Average loss: 0.001544\n",
      "Validation set: Average loss: 0.000604, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 27\n",
      "Training set [0/840 (0%)] Loss: 0.000407\n",
      "Training set [500/840 (59%)] Loss: 0.000722\n",
      "Training set: Average loss: 0.000939\n",
      "Validation set: Average loss: 0.000369, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 28\n",
      "Training set [0/840 (0%)] Loss: 0.000877\n",
      "Training set [500/840 (59%)] Loss: 0.000544\n",
      "Training set: Average loss: 0.001112\n",
      "Validation set: Average loss: 0.000334, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 29\n",
      "Training set [0/840 (0%)] Loss: 0.000067\n",
      "Training set [500/840 (59%)] Loss: 0.000113\n",
      "Training set: Average loss: 0.000540\n",
      "Validation set: Average loss: 0.000295, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 30\n",
      "Training set [0/840 (0%)] Loss: 0.000195\n",
      "Training set [500/840 (59%)] Loss: 0.000206\n",
      "Training set: Average loss: 0.000591\n",
      "Validation set: Average loss: 0.000266, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 31\n",
      "Training set [0/840 (0%)] Loss: 0.001124\n",
      "Training set [500/840 (59%)] Loss: 0.000479\n",
      "Training set: Average loss: 0.000264\n",
      "Validation set: Average loss: 0.000234, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 32\n",
      "Training set [0/840 (0%)] Loss: 0.000124\n",
      "Training set [500/840 (59%)] Loss: 0.000080\n",
      "Training set: Average loss: 0.000206\n",
      "Validation set: Average loss: 0.000190, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 33\n",
      "Training set [0/840 (0%)] Loss: 0.001023\n",
      "Training set [500/840 (59%)] Loss: 0.000355\n",
      "Training set: Average loss: 0.001589\n",
      "Validation set: Average loss: 0.001113, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 34\n",
      "Training set [0/840 (0%)] Loss: 0.003400\n",
      "Training set [500/840 (59%)] Loss: 0.001123\n",
      "Training set: Average loss: 0.001529\n",
      "Validation set: Average loss: 0.000538, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 35\n",
      "Training set [0/840 (0%)] Loss: 0.002004\n",
      "Training set [500/840 (59%)] Loss: 0.000121\n",
      "Training set: Average loss: 0.000367\n",
      "Validation set: Average loss: 0.000241, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 36\n",
      "Training set [0/840 (0%)] Loss: 0.000106\n",
      "Training set [500/840 (59%)] Loss: 0.000192\n",
      "Training set: Average loss: 0.001116\n",
      "Validation set: Average loss: 0.000365, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 37\n",
      "Training set [0/840 (0%)] Loss: 0.002517\n",
      "Training set [500/840 (59%)] Loss: 0.000053\n",
      "Training set: Average loss: 0.000862\n",
      "Validation set: Average loss: 0.000899, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 38\n",
      "Training set [0/840 (0%)] Loss: 0.002131\n",
      "Training set [500/840 (59%)] Loss: 0.004033\n",
      "Training set: Average loss: 0.000825\n",
      "Validation set: Average loss: 0.000199, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 39\n",
      "Training set [0/840 (0%)] Loss: 0.000515\n",
      "Training set [500/840 (59%)] Loss: 0.000113\n",
      "Training set: Average loss: 0.000290\n",
      "Validation set: Average loss: 0.000270, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 40\n",
      "Training set [0/840 (0%)] Loss: 0.000114\n",
      "Training set [500/840 (59%)] Loss: 0.000817\n",
      "Training set: Average loss: 0.001884\n",
      "Validation set: Average loss: 0.000255, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 41\n",
      "Training set [0/840 (0%)] Loss: 0.000065\n",
      "Training set [500/840 (59%)] Loss: 0.005661\n",
      "Training set: Average loss: 0.001219\n",
      "Validation set: Average loss: 0.000349, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 42\n",
      "Training set [0/840 (0%)] Loss: 0.000018\n",
      "Training set [500/840 (59%)] Loss: 0.000113\n",
      "Training set: Average loss: 0.000766\n",
      "Validation set: Average loss: 0.001409, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 43\n",
      "Training set [0/840 (0%)] Loss: 0.000396\n",
      "Training set [500/840 (59%)] Loss: 0.001350\n",
      "Training set: Average loss: 0.004553\n",
      "Validation set: Average loss: 0.000240, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 44\n",
      "Training set [0/840 (0%)] Loss: 0.000075\n",
      "Training set [500/840 (59%)] Loss: 0.000098\n",
      "Training set: Average loss: 0.001293\n",
      "Validation set: Average loss: 0.001481, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 45\n",
      "Training set [0/840 (0%)] Loss: 0.007187\n",
      "Training set [500/840 (59%)] Loss: 0.000083\n",
      "Training set: Average loss: 0.000710\n",
      "Validation set: Average loss: 0.000188, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 46\n",
      "Training set [0/840 (0%)] Loss: 0.000055\n",
      "Training set [500/840 (59%)] Loss: 0.000026\n",
      "Training set: Average loss: 0.000877\n",
      "Validation set: Average loss: 0.000307, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 47\n",
      "Training set [0/840 (0%)] Loss: 0.001155\n",
      "Training set [500/840 (59%)] Loss: 0.001833\n",
      "Training set: Average loss: 0.001384\n",
      "Validation set: Average loss: 0.000307, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 48\n",
      "Training set [0/840 (0%)] Loss: 0.000024\n",
      "Training set [500/840 (59%)] Loss: 0.000033\n",
      "Training set: Average loss: 0.001713\n",
      "Validation set: Average loss: 0.000354, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 49\n",
      "Training set [0/840 (0%)] Loss: 0.000090\n",
      "Training set [500/840 (59%)] Loss: 0.000224\n",
      "Training set: Average loss: 0.000815\n",
      "Validation set: Average loss: 0.000202, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 50\n",
      "Training set [0/840 (0%)] Loss: 0.000408\n",
      "Training set [500/840 (59%)] Loss: 0.000075\n",
      "Training set: Average loss: 0.000726\n",
      "Validation set: Average loss: 0.000224, Accuracy: 360/360 (100%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_nums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
    "training_loss = [1.0012142728356754, 0.5135973306263194, 0.2907167567926295, 0.1566463686964091, 0.12172643533524345, 0.0652787965886733, 0.04081264992847162, 0.038378451074309206, 0.0345699954777956, 0.02172902746893027, 0.03890544439063353, 0.016187263695482054, 0.007589282118715346, 0.008064666937571019, 0.006214961878654054, 0.015086331000715932, 0.013507066907443325, 0.01477325233110391, 0.007408273416598711, 0.004513079639496829, 0.005367005959509269, 0.003934128608842216, 0.0015826551774379743, 0.002613745237741729, 0.0023829116390141495, 0.0014075274670818437, 0.0008194782218625358, 0.0008938396315309493, 0.0006066296880496392, 0.0006166334582410534, 0.001401052661736578, 0.006307438349026865, 0.0022078641460907154, 0.0026143413619780296, 0.0021404172713279396, 0.0015406526149223175, 0.001366157220913652, 0.0005554087545747546, 0.0005784737281561213, 0.000593931621979744, 0.0004682258027862511, 0.0017148349452862236, 0.0003167820304952329, 0.000127819750131868, 0.00020441709415643024, 0.00018004282628680812, 0.00031255880789745683, 0.00017861491767903585, 0.0005856147971130934, 0.0020370626931681354]\n",
    "validation_loss = [0.6673303097486496, 0.30568786710500717, 0.1965186232700944, 0.10293586342595518, 0.06530656665563583, 0.04304971219971776, 0.022525178152136505, 0.01790400079335086, 0.013899762998335063, 0.014631185069447383, 0.015811252873390913, 0.010235420180833898, 0.004511535444180481, 0.003531531625412754, 0.005147198820168342, 0.005417024754024169, 0.0028075429545424413, 0.004791191813751539, 0.0021507866513275076, 0.0024289254579343833, 0.00194900297174172, 0.0013920017663622275, 0.0015894820180619718, 0.0009377644146297826, 0.0008549574049538933, 0.0006199660510901595, 0.0006358291575452313, 0.0005021533347644436, 0.00048047361360659124, 0.0004245713819273078, 0.0003946199022948349, 0.0006263376369588514, 0.0006867554110385754, 0.0007179843737219471, 0.0004158226377057872, 0.000575107684426257, 0.00067178004633206, 0.00025096282527670155, 0.00025330326118933044, 0.0002704071770125438, 0.00023775113023560834, 0.0005064000172581018, 0.0002101199740991433, 0.00017247251301455435, 0.00015352206485630404, 0.00014542134262995887, 0.0001605216949585042, 0.0001472401715716387, 0.000486813393678176, 0.0006943353153303633]\n",
    "\n",
    "training_results = \"\"\"\n",
    "Epoch: 1\n",
    "Training set [0/840 (0%)] Loss: 1.103770\n",
    "Training set [500/840 (59%)] Loss: 0.767837\n",
    "Training set: Average loss: 0.825230\n",
    "Validation set: Average loss: 0.476628, Accuracy: 290/360 (81%)\n",
    "\n",
    "Epoch: 2\n",
    "Training set [0/840 (0%)] Loss: 0.511575\n",
    "Training set [500/840 (59%)] Loss: 0.308371\n",
    "Training set: Average loss: 0.388326\n",
    "Validation set: Average loss: 0.301778, Accuracy: 302/360 (84%)\n",
    "\n",
    "Epoch: 3\n",
    "Training set [0/840 (0%)] Loss: 0.354706\n",
    "Training set [500/840 (59%)] Loss: 0.261062\n",
    "Training set: Average loss: 0.256638\n",
    "Validation set: Average loss: 0.168473, Accuracy: 335/360 (93%)\n",
    "\n",
    "Epoch: 4\n",
    "Training set [0/840 (0%)] Loss: 0.168978\n",
    "Training set [500/840 (59%)] Loss: 0.117388\n",
    "Training set: Average loss: 0.138040\n",
    "Validation set: Average loss: 0.090180, Accuracy: 351/360 (98%)\n",
    "\n",
    "Epoch: 5\n",
    "Training set [0/840 (0%)] Loss: 0.100226\n",
    "Training set [500/840 (59%)] Loss: 0.065538\n",
    "Training set: Average loss: 0.071896\n",
    "Validation set: Average loss: 0.044922, Accuracy: 356/360 (99%)\n",
    "\n",
    "Epoch: 6\n",
    "Training set [0/840 (0%)] Loss: 0.034637\n",
    "Training set [500/840 (59%)] Loss: 0.036014\n",
    "Training set: Average loss: 0.043303\n",
    "Validation set: Average loss: 0.023202, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 7\n",
    "Training set [0/840 (0%)] Loss: 0.022999\n",
    "Training set [500/840 (59%)] Loss: 0.055200\n",
    "Training set: Average loss: 0.034087\n",
    "Validation set: Average loss: 0.022698, Accuracy: 357/360 (99%)\n",
    "\n",
    "Epoch: 8\n",
    "Training set [0/840 (0%)] Loss: 0.029490\n",
    "Training set [500/840 (59%)] Loss: 0.018004\n",
    "Training set: Average loss: 0.041226\n",
    "Validation set: Average loss: 0.018746, Accuracy: 359/360 (100%)\n",
    "\n",
    "Epoch: 9\n",
    "Training set [0/840 (0%)] Loss: 0.019401\n",
    "Training set [500/840 (59%)] Loss: 0.008904\n",
    "Training set: Average loss: 0.018305\n",
    "Validation set: Average loss: 0.009203, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 10\n",
    "Training set [0/840 (0%)] Loss: 0.016958\n",
    "Training set [500/840 (59%)] Loss: 0.013551\n",
    "Training set: Average loss: 0.012223\n",
    "Validation set: Average loss: 0.005830, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 11\n",
    "Training set [0/840 (0%)] Loss: 0.020725\n",
    "Training set [500/840 (59%)] Loss: 0.007458\n",
    "Training set: Average loss: 0.017074\n",
    "Validation set: Average loss: 0.004759, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 12\n",
    "Training set [0/840 (0%)] Loss: 0.006093\n",
    "Training set [500/840 (59%)] Loss: 0.003227\n",
    "Training set: Average loss: 0.008680\n",
    "Validation set: Average loss: 0.002621, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 13\n",
    "Training set [0/840 (0%)] Loss: 0.008323\n",
    "Training set [500/840 (59%)] Loss: 0.003433\n",
    "Training set: Average loss: 0.004586\n",
    "Validation set: Average loss: 0.003536, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 14\n",
    "Training set [0/840 (0%)] Loss: 0.005679\n",
    "Training set [500/840 (59%)] Loss: 0.002220\n",
    "Training set: Average loss: 0.003429\n",
    "Validation set: Average loss: 0.002008, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 15\n",
    "Training set [0/840 (0%)] Loss: 0.008813\n",
    "Training set [500/840 (59%)] Loss: 0.001869\n",
    "Training set: Average loss: 0.005016\n",
    "Validation set: Average loss: 0.003085, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 16\n",
    "Training set [0/840 (0%)] Loss: 0.010281\n",
    "Training set [500/840 (59%)] Loss: 0.002442\n",
    "Training set: Average loss: 0.003687\n",
    "Validation set: Average loss: 0.001785, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 17\n",
    "Training set [0/840 (0%)] Loss: 0.004554\n",
    "Training set [500/840 (59%)] Loss: 0.000509\n",
    "Training set: Average loss: 0.004108\n",
    "Validation set: Average loss: 0.001743, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 18\n",
    "Training set [0/840 (0%)] Loss: 0.003746\n",
    "Training set [500/840 (59%)] Loss: 0.000447\n",
    "Training set: Average loss: 0.004889\n",
    "Validation set: Average loss: 0.003176, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 19\n",
    "Training set [0/840 (0%)] Loss: 0.010371\n",
    "Training set [500/840 (59%)] Loss: 0.005106\n",
    "Training set: Average loss: 0.004751\n",
    "Validation set: Average loss: 0.002028, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 20\n",
    "Training set [0/840 (0%)] Loss: 0.002068\n",
    "Training set [500/840 (59%)] Loss: 0.000766\n",
    "Training set: Average loss: 0.002941\n",
    "Validation set: Average loss: 0.001435, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 21\n",
    "Training set [0/840 (0%)] Loss: 0.005506\n",
    "Training set [500/840 (59%)] Loss: 0.000672\n",
    "Training set: Average loss: 0.004504\n",
    "Validation set: Average loss: 0.000623, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 22\n",
    "Training set [0/840 (0%)] Loss: 0.000773\n",
    "Training set [500/840 (59%)] Loss: 0.000171\n",
    "Training set: Average loss: 0.002254\n",
    "Validation set: Average loss: 0.000901, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 23\n",
    "Training set [0/840 (0%)] Loss: 0.000373\n",
    "Training set [500/840 (59%)] Loss: 0.000964\n",
    "Training set: Average loss: 0.001514\n",
    "Validation set: Average loss: 0.000947, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 24\n",
    "Training set [0/840 (0%)] Loss: 0.003218\n",
    "Training set [500/840 (59%)] Loss: 0.001212\n",
    "Training set: Average loss: 0.001670\n",
    "Validation set: Average loss: 0.000543, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 25\n",
    "Training set [0/840 (0%)] Loss: 0.000807\n",
    "Training set [500/840 (59%)] Loss: 0.000227\n",
    "Training set: Average loss: 0.001656\n",
    "Validation set: Average loss: 0.000662, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 26\n",
    "Training set [0/840 (0%)] Loss: 0.003577\n",
    "Training set [500/840 (59%)] Loss: 0.001073\n",
    "Training set: Average loss: 0.001544\n",
    "Validation set: Average loss: 0.000604, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 27\n",
    "Training set [0/840 (0%)] Loss: 0.000407\n",
    "Training set [500/840 (59%)] Loss: 0.000722\n",
    "Training set: Average loss: 0.000939\n",
    "Validation set: Average loss: 0.000369, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 28\n",
    "Training set [0/840 (0%)] Loss: 0.000877\n",
    "Training set [500/840 (59%)] Loss: 0.000544\n",
    "Training set: Average loss: 0.001112\n",
    "Validation set: Average loss: 0.000334, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 29\n",
    "Training set [0/840 (0%)] Loss: 0.000067\n",
    "Training set [500/840 (59%)] Loss: 0.000113\n",
    "Training set: Average loss: 0.000540\n",
    "Validation set: Average loss: 0.000295, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 30\n",
    "Training set [0/840 (0%)] Loss: 0.000195\n",
    "Training set [500/840 (59%)] Loss: 0.000206\n",
    "Training set: Average loss: 0.000591\n",
    "Validation set: Average loss: 0.000266, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 31\n",
    "Training set [0/840 (0%)] Loss: 0.001124\n",
    "Training set [500/840 (59%)] Loss: 0.000479\n",
    "Training set: Average loss: 0.000264\n",
    "Validation set: Average loss: 0.000234, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 32\n",
    "Training set [0/840 (0%)] Loss: 0.000124\n",
    "Training set [500/840 (59%)] Loss: 0.000080\n",
    "Training set: Average loss: 0.000206\n",
    "Validation set: Average loss: 0.000190, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 33\n",
    "Training set [0/840 (0%)] Loss: 0.001023\n",
    "Training set [500/840 (59%)] Loss: 0.000355\n",
    "Training set: Average loss: 0.001589\n",
    "Validation set: Average loss: 0.001113, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 34\n",
    "Training set [0/840 (0%)] Loss: 0.003400\n",
    "Training set [500/840 (59%)] Loss: 0.001123\n",
    "Training set: Average loss: 0.001529\n",
    "Validation set: Average loss: 0.000538, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 35\n",
    "Training set [0/840 (0%)] Loss: 0.002004\n",
    "Training set [500/840 (59%)] Loss: 0.000121\n",
    "Training set: Average loss: 0.000367\n",
    "Validation set: Average loss: 0.000241, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 36\n",
    "Training set [0/840 (0%)] Loss: 0.000106\n",
    "Training set [500/840 (59%)] Loss: 0.000192\n",
    "Training set: Average loss: 0.001116\n",
    "Validation set: Average loss: 0.000365, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 37\n",
    "Training set [0/840 (0%)] Loss: 0.002517\n",
    "Training set [500/840 (59%)] Loss: 0.000053\n",
    "Training set: Average loss: 0.000862\n",
    "Validation set: Average loss: 0.000899, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 38\n",
    "Training set [0/840 (0%)] Loss: 0.002131\n",
    "Training set [500/840 (59%)] Loss: 0.004033\n",
    "Training set: Average loss: 0.000825\n",
    "Validation set: Average loss: 0.000199, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 39\n",
    "Training set [0/840 (0%)] Loss: 0.000515\n",
    "Training set [500/840 (59%)] Loss: 0.000113\n",
    "Training set: Average loss: 0.000290\n",
    "Validation set: Average loss: 0.000270, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 40\n",
    "Training set [0/840 (0%)] Loss: 0.000114\n",
    "Training set [500/840 (59%)] Loss: 0.000817\n",
    "Training set: Average loss: 0.001884\n",
    "Validation set: Average loss: 0.000255, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 41\n",
    "Training set [0/840 (0%)] Loss: 0.000065\n",
    "Training set [500/840 (59%)] Loss: 0.005661\n",
    "Training set: Average loss: 0.001219\n",
    "Validation set: Average loss: 0.000349, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 42\n",
    "Training set [0/840 (0%)] Loss: 0.000018\n",
    "Training set [500/840 (59%)] Loss: 0.000113\n",
    "Training set: Average loss: 0.000766\n",
    "Validation set: Average loss: 0.001409, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 43\n",
    "Training set [0/840 (0%)] Loss: 0.000396\n",
    "Training set [500/840 (59%)] Loss: 0.001350\n",
    "Training set: Average loss: 0.004553\n",
    "Validation set: Average loss: 0.000240, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 44\n",
    "Training set [0/840 (0%)] Loss: 0.000075\n",
    "Training set [500/840 (59%)] Loss: 0.000098\n",
    "Training set: Average loss: 0.001293\n",
    "Validation set: Average loss: 0.001481, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 45\n",
    "Training set [0/840 (0%)] Loss: 0.007187\n",
    "Training set [500/840 (59%)] Loss: 0.000083\n",
    "Training set: Average loss: 0.000710\n",
    "Validation set: Average loss: 0.000188, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 46\n",
    "Training set [0/840 (0%)] Loss: 0.000055\n",
    "Training set [500/840 (59%)] Loss: 0.000026\n",
    "Training set: Average loss: 0.000877\n",
    "Validation set: Average loss: 0.000307, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 47\n",
    "Training set [0/840 (0%)] Loss: 0.001155\n",
    "Training set [500/840 (59%)] Loss: 0.001833\n",
    "Training set: Average loss: 0.001384\n",
    "Validation set: Average loss: 0.000307, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 48\n",
    "Training set [0/840 (0%)] Loss: 0.000024\n",
    "Training set [500/840 (59%)] Loss: 0.000033\n",
    "Training set: Average loss: 0.001713\n",
    "Validation set: Average loss: 0.000354, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 49\n",
    "Training set [0/840 (0%)] Loss: 0.000090\n",
    "Training set [500/840 (59%)] Loss: 0.000224\n",
    "Training set: Average loss: 0.000815\n",
    "Validation set: Average loss: 0.000202, Accuracy: 360/360 (100%)\n",
    "\n",
    "Epoch: 50\n",
    "Training set [0/840 (0%)] Loss: 0.000408\n",
    "Training set [500/840 (59%)] Loss: 0.000075\n",
    "Training set: Average loss: 0.000726\n",
    "Validation set: Average loss: 0.000224, Accuracy: 360/360 (100%)\"\"\"\n",
    "\n",
    "print(training_results)\n",
    "\n",
    "# Load previously saved model\n",
    "model_file = 'models/shape_classifier.pt'\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(model_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. View the loss history\n",
    "\n",
    "The average training and validation loss for each epoch are plotted on a graph to verify that loss is reduced as the model was trained, and to detect *over-fitting* (which is indicated by a continued drop in training loss after validation loss has levelled out or started to increase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate model performance\n",
    "\n",
    "A confusion matrix is plotted to see how well the model is predicting each class of image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from test set...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the model to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "# Get predictions for the test data and convert to numpy arrays for use with SciKit-Learn\n",
    "print(\"Getting predictions from test set...\")\n",
    "truelabels = []\n",
    "predictions = []\n",
    "for data, target in test_loader:\n",
    "    for label in target.cpu().data.numpy():\n",
    "        truelabels.append(label)\n",
    "    for prediction in model.cpu()(data).data.numpy().argmax(1):\n",
    "        predictions.append(prediction) \n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(truelabels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel(\"Actual Shape\")\n",
    "plt.ylabel(\"Predicted Shape\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use the trained model\n",
    "\n",
    "The model can now be used to predict classes for new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-eb9f4ff0d586>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# Save the model weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mmodel_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'models/shape_classifier.pt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image):\n",
    "    import numpy\n",
    "    \n",
    "    # Set the classifer model to evaluation mode\n",
    "    classifier.eval()\n",
    "    \n",
    "    # Apply the same transformations as we did for the training images\n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Preprocess the image\n",
    "    image_tensor = transformation(image).float()\n",
    "\n",
    "    # Add an extra batch dimension since pytorch treats all inputs as batches\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "\n",
    "    # Turn the input into a Variable\n",
    "    input_features = Variable(image_tensor)\n",
    "\n",
    "    # Predict the class of the image\n",
    "    output = classifier(input_features)\n",
    "    index = output.data.numpy().argmax()\n",
    "    return index\n",
    "\n",
    "\n",
    "# Function to create a random image (of a square, circle, or triangle)\n",
    "def create_image (size, shape): \n",
    "    xy1 = randint(10,40)\n",
    "    xy2 = randint(60,100)\n",
    "    col = (randint(0,200), randint(0,200), randint(0,200))\n",
    "\n",
    "    img = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    elif shape == 'triangle':\n",
    "        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n",
    "    else: # square\n",
    "        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    del draw\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "# Save the model weights\n",
    "model_file = 'models/shape_classifier.pt'\n",
    "torch.save(model.state_dict(), model_file)\n",
    "\n",
    "out = widgets.Output(layout={'border': '0.5px solid black'})\n",
    "\n",
    "def predict_Shape(button):\n",
    "    # Create a random test image\n",
    "    classnames = os.listdir(os.path.join('data', 'shapes'))\n",
    "    classnames.sort()\n",
    "    shape = classnames[randint(0, len(classnames)-1)]\n",
    "    img = create_image ((128,128), shape)\n",
    "    \n",
    "    # Create a new model class and load weights\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    # Call the predction function\n",
    "    index = predict_image(model, img)\n",
    "    global out\n",
    "    # Display the image\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    with out:\n",
    "        print('The predicted shape is:', classes[index])\n",
    "        \n",
    "predict_button=widgets.Button(\n",
    "description='Predict Shape',\n",
    "disabled=False,\n",
    "button_style='primary', \n",
    "tooltip=\"Click to randomly create a shape and see if the CNN correctly predicted it\",\n",
    "icon='refresh')\n",
    "\n",
    "button_form = widgets.VBox([predict_button, out])\n",
    "\n",
    "display(button_form)\n",
    "\n",
    "predict_button.on_click(predict_Shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
